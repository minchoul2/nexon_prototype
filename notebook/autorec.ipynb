{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_1 = pd.read_csv('../input/payco_23.csv')\n",
    "data_2 = pd.read_csv('../input/payco_2304.csv')\n",
    "df = pd.concat([data_1,data_2])\n",
    "df = data_2[['사원번호','사용처']].rename({'사원번호':'userid', '사용처':'itemid'}, axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create user-item matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create a new DataFrame with frequency count for each user-item pair\n",
    "df_grouped = df.groupby(['userid', 'itemid']).size().reset_index(name='frequency')\n",
    "\n",
    "user_u = list(sorted(df_grouped.userid.unique()))\n",
    "item_u = list(sorted(df_grouped.itemid.unique()))\n",
    "\n",
    "user_c = CategoricalDtype(sorted(df_grouped['userid'].unique()), ordered=True)\n",
    "item_c = CategoricalDtype(sorted(df_grouped['itemid'].unique()), ordered=True)\n",
    "\n",
    "row = df_grouped['userid'].astype(user_c).cat.codes\n",
    "col = df_grouped['itemid'].astype(item_c).cat.codes\n",
    "data = df_grouped['frequency'].tolist()\n",
    "\n",
    "sparse_matrix = csr_matrix((data, (row, col)), shape=(len(user_u), len(item_u)))\n",
    "\n",
    "df_user_item = pd.DataFrame.sparse.from_spmatrix(sparse_matrix, index=user_u, columns=item_u)\n",
    "df_user_item.to_pickle('../input/user_item.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define AutoRec model\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_units):\n",
    "        super(AutoRec, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Linear(num_inputs, hidden_units)\n",
    "        self.decoder = nn.Linear(hidden_units, num_inputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.encoder(x))\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train and Test AutoRec model\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_units = 500\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = AutoRec(df_user_item.shape[1], hidden_units).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "data = torch.FloatTensor(df_user_item.values).to(device)\n",
    "dataset = TensorDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.031754862517118454\n",
      "Minimum Loss Dropped to 0.031754862517118454 at epoch 1, saving model...\n",
      "Epoch 2/100, Loss: 0.023758795112371445\n",
      "Minimum Loss Dropped to 0.023758795112371445 at epoch 2, saving model...\n",
      "Epoch 3/100, Loss: 0.02415415830910206\n",
      "Epoch 4/100, Loss: 0.016433265060186386\n",
      "Minimum Loss Dropped to 0.016433265060186386 at epoch 4, saving model...\n",
      "Epoch 5/100, Loss: 0.012687739916145802\n",
      "Minimum Loss Dropped to 0.012687739916145802 at epoch 5, saving model...\n",
      "Epoch 6/100, Loss: 0.008689253591001034\n",
      "Minimum Loss Dropped to 0.008689253591001034 at epoch 6, saving model...\n",
      "Epoch 7/100, Loss: 0.010366234928369522\n",
      "Epoch 8/100, Loss: 0.004158169496804476\n",
      "Minimum Loss Dropped to 0.004158169496804476 at epoch 8, saving model...\n",
      "Epoch 9/100, Loss: 0.004018498118966818\n",
      "Minimum Loss Dropped to 0.004018498118966818 at epoch 9, saving model...\n",
      "Epoch 10/100, Loss: 0.002779238624498248\n",
      "Minimum Loss Dropped to 0.002779238624498248 at epoch 10, saving model...\n",
      "Epoch 11/100, Loss: 0.002287545008584857\n",
      "Minimum Loss Dropped to 0.002287545008584857 at epoch 11, saving model...\n",
      "Epoch 12/100, Loss: 0.0016725591849535704\n",
      "Minimum Loss Dropped to 0.0016725591849535704 at epoch 12, saving model...\n",
      "Epoch 13/100, Loss: 0.0019050919217988849\n",
      "Epoch 14/100, Loss: 0.0010625834111124277\n",
      "Minimum Loss Dropped to 0.0010625834111124277 at epoch 14, saving model...\n",
      "Epoch 15/100, Loss: 0.0012338486267253757\n",
      "Epoch 16/100, Loss: 0.0010482448851689696\n",
      "Minimum Loss Dropped to 0.0010482448851689696 at epoch 16, saving model...\n",
      "Epoch 17/100, Loss: 0.000894413678906858\n",
      "Minimum Loss Dropped to 0.000894413678906858 at epoch 17, saving model...\n",
      "Epoch 18/100, Loss: 0.0008452693582512438\n",
      "Minimum Loss Dropped to 0.0008452693582512438 at epoch 18, saving model...\n",
      "Epoch 19/100, Loss: 0.001401108456775546\n",
      "Epoch 20/100, Loss: 0.0007675195811316371\n",
      "Minimum Loss Dropped to 0.0007675195811316371 at epoch 20, saving model...\n",
      "Epoch 21/100, Loss: 0.00031839575967751443\n",
      "Minimum Loss Dropped to 0.00031839575967751443 at epoch 21, saving model...\n",
      "Epoch 22/100, Loss: 0.00036147257196716964\n",
      "Epoch 23/100, Loss: 0.00030914077069610357\n",
      "Minimum Loss Dropped to 0.00030914077069610357 at epoch 23, saving model...\n",
      "Epoch 24/100, Loss: 0.00042955210665240884\n",
      "Epoch 25/100, Loss: 0.00046733382623642683\n",
      "Epoch 26/100, Loss: 0.00038255538675002754\n",
      "Epoch 27/100, Loss: 0.0002769202401395887\n",
      "Minimum Loss Dropped to 0.0002769202401395887 at epoch 27, saving model...\n",
      "Epoch 28/100, Loss: 0.00028902513440698385\n",
      "Epoch 29/100, Loss: 0.0001815215655369684\n",
      "Minimum Loss Dropped to 0.0001815215655369684 at epoch 29, saving model...\n",
      "Epoch 30/100, Loss: 0.0003833300434052944\n",
      "Epoch 31/100, Loss: 0.0001963200484169647\n",
      "Epoch 32/100, Loss: 0.00027068264898844063\n",
      "Epoch 33/100, Loss: 0.000307639769744128\n",
      "Epoch 34/100, Loss: 0.00019208743469789624\n",
      "Epoch 35/100, Loss: 0.00014353547885548323\n",
      "Minimum Loss Dropped to 0.00014353547885548323 at epoch 35, saving model...\n",
      "Epoch 36/100, Loss: 0.00017327863315586\n",
      "Epoch 37/100, Loss: 0.00021173025015741587\n",
      "Epoch 38/100, Loss: 0.0003171761054545641\n",
      "Epoch 39/100, Loss: 0.00018963754700962454\n",
      "Epoch 40/100, Loss: 8.91384988790378e-05\n",
      "Minimum Loss Dropped to 8.91384988790378e-05 at epoch 40, saving model...\n",
      "Epoch 41/100, Loss: 8.608328062109649e-05\n",
      "Minimum Loss Dropped to 8.608328062109649e-05 at epoch 41, saving model...\n",
      "Epoch 42/100, Loss: 0.00012770867033395916\n",
      "Epoch 43/100, Loss: 0.00012944005720783025\n",
      "Epoch 44/100, Loss: 0.00022100952628534287\n",
      "Epoch 45/100, Loss: 0.00016500554920639843\n",
      "Epoch 46/100, Loss: 0.00014596643450204283\n",
      "Epoch 47/100, Loss: 0.0002140299038728699\n",
      "Epoch 48/100, Loss: 0.00011211002856725827\n",
      "Epoch 49/100, Loss: 0.0001019679184537381\n",
      "Epoch 50/100, Loss: 9.698908979771659e-05\n",
      "Epoch 51/100, Loss: 8.074266224866733e-05\n",
      "Minimum Loss Dropped to 8.074266224866733e-05 at epoch 51, saving model...\n",
      "Epoch 52/100, Loss: 0.00010871607082663104\n",
      "Epoch 53/100, Loss: 0.00011007492139469832\n",
      "Epoch 54/100, Loss: 9.695089102024212e-05\n",
      "Epoch 55/100, Loss: 0.00014235390699468553\n",
      "Epoch 56/100, Loss: 0.0001491699949838221\n",
      "Epoch 57/100, Loss: 7.194900535978377e-05\n",
      "Minimum Loss Dropped to 7.194900535978377e-05 at epoch 57, saving model...\n",
      "Epoch 58/100, Loss: 7.634051144123077e-05\n",
      "Epoch 59/100, Loss: 8.279975736513734e-05\n",
      "Epoch 60/100, Loss: 0.00016190837777685374\n",
      "Epoch 61/100, Loss: 9.351262269774452e-05\n",
      "Epoch 62/100, Loss: 0.00011494331556605175\n",
      "Epoch 63/100, Loss: 8.7746448116377e-05\n",
      "Epoch 64/100, Loss: 9.052515815710649e-05\n",
      "Epoch 65/100, Loss: 8.202070603147149e-05\n",
      "Epoch 66/100, Loss: 8.604042523074895e-05\n",
      "Epoch 67/100, Loss: 0.0001163669367088005\n",
      "Epoch 68/100, Loss: 0.00010820502939168364\n",
      "Epoch 69/100, Loss: 0.00010964361717924476\n",
      "Epoch 70/100, Loss: 9.501192107563838e-05\n",
      "Epoch 71/100, Loss: 0.00010481904610060155\n",
      "Epoch 72/100, Loss: 8.978662663139403e-05\n",
      "Epoch 73/100, Loss: 9.101939940592274e-05\n",
      "Epoch 74/100, Loss: 0.00010649848991306499\n",
      "Epoch 75/100, Loss: 9.012208465719596e-05\n",
      "Epoch 76/100, Loss: 8.965671440819278e-05\n",
      "Epoch 77/100, Loss: 0.00011167608317919075\n",
      "Epoch 78/100, Loss: 0.00012231050641275942\n",
      "Epoch 79/100, Loss: 0.00012497910938691348\n",
      "Epoch 80/100, Loss: 8.809810969978571e-05\n",
      "Epoch 81/100, Loss: 9.424374729860574e-05\n",
      "Epoch 82/100, Loss: 0.00017263274639844894\n",
      "Epoch 83/100, Loss: 8.721111953491345e-05\n",
      "Epoch 84/100, Loss: 9.095898712985218e-05\n",
      "Epoch 85/100, Loss: 7.531114533776417e-05\n",
      "Epoch 86/100, Loss: 8.198828436434269e-05\n",
      "Epoch 87/100, Loss: 7.802509935572743e-05\n",
      "Epoch 88/100, Loss: 8.259947935584933e-05\n",
      "Epoch 89/100, Loss: 0.000122358207590878\n",
      "Epoch 90/100, Loss: 0.00010473630391061306\n",
      "Epoch 91/100, Loss: 8.455157512798905e-05\n",
      "Epoch 92/100, Loss: 7.866405212553218e-05\n",
      "Epoch 93/100, Loss: 8.287031960207969e-05\n",
      "Epoch 94/100, Loss: 9.335898357676342e-05\n",
      "Epoch 95/100, Loss: 8.033868653001264e-05\n",
      "Epoch 96/100, Loss: 7.630488107679412e-05\n",
      "Epoch 97/100, Loss: 0.00010054445738205686\n",
      "Epoch 98/100, Loss: 8.30180651973933e-05\n",
      "Epoch 99/100, Loss: 7.570747402496636e-05\n",
      "Epoch 100/100, Loss: 9.241198131348938e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "model.train()\n",
    "min_loss = np.inf  # 초기의 최소 loss를 무한대로 설정\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs,) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    # If the current model has the lowest loss, save it\n",
    "    if loss.item() < min_loss:\n",
    "        print(f\"Minimum Loss Dropped to {loss.item()} at epoch {epoch+1}, saving model...\")\n",
    "        torch.save(model.state_dict(), '../input/autorec_best_model.pt')\n",
    "        min_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0188,  0.0150, -0.0262,  ..., -0.0051, -0.0026, -0.0056],\n",
      "        [-0.0185,  0.0048, -0.0264,  ..., -0.0027, -0.0037, -0.0038],\n",
      "        [-0.0177,  0.0093, -0.0258,  ..., -0.0054, -0.0050, -0.0057],\n",
      "        ...,\n",
      "        [-0.0210,  0.0475,  0.0100,  ..., -0.0030,  0.0083,  0.0065],\n",
      "        [-0.0202,  0.0155, -0.0195,  ..., -0.0058, -0.0050, -0.0057],\n",
      "        [-0.0266,  0.0387,  0.0035,  ...,  0.0198,  0.0086, -0.0039]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "num_inputs = df_user_item.shape[1]  # 이전에 사용한 입력 차원의 수\n",
    "hidden_units = 500  # 이전에 사용한 hidden layer의 unit 수\n",
    "\n",
    "model = AutoRec(num_inputs, hidden_units)\n",
    "\n",
    "# CPU나 GPU 중에서 사용 가능한 장치를 선택\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델을 해당 장치로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 저장된 모델의 가중치를 불러오기\n",
    "model.load_state_dict(torch.load('autorec_best_model.pt'))\n",
    "\n",
    "# 모델을 평가 모드로 설정 (dropout이나 batch normalization 등의 동작을 평가 모드로 바꿉니다)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = data\n",
    "    outputs = model(inputs)\n",
    "    print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate recommendations\n",
    "import numpy as np\n",
    "\n",
    "def user_free_inference(items, df_user_item, model, top_k=10):\n",
    "    # Create a new user vector\n",
    "    user_vector = np.zeros(df_user_item.shape[1])\n",
    "    item_indices = []\n",
    "\n",
    "    # Set the chosen items to the maximum value\n",
    "    for item in items:\n",
    "        if item in df_user_item.columns:\n",
    "            item_index = df_user_item.columns.get_loc(item)\n",
    "            user_vector[item_index] = df_user_item.values.max()\n",
    "            item_indices.append(item_index)\n",
    "        else:\n",
    "            raise ValueError(f\"Item {item} not found in the data\")\n",
    "\n",
    "    # Convert to tensor and move to the correct device\n",
    "    user_vector = torch.FloatTensor([user_vector]).to(device)\n",
    "\n",
    "    # Generate recommendations\n",
    "    with torch.no_grad():\n",
    "        outputs = model(user_vector)\n",
    "        predicted_ratings = outputs.cpu().numpy()[0]\n",
    "\n",
    "    # Remove the chosen items from the predictions\n",
    "    predicted_ratings[item_indices] = -np.inf\n",
    "\n",
    "    top_k_item_indices = np.argsort(-predicted_ratings)[:top_k]\n",
    "    recommended_items = df_user_item.columns[top_k_item_indices]\n",
    "    recommended_scores = predicted_ratings[top_k_item_indices]\n",
    "\n",
    "    # Convert item and score to dictionary\n",
    "    item_score_dict = dict(zip(recommended_items.tolist(), recommended_scores.tolist()))\n",
    "\n",
    "    # Print each item and it score\n",
    "    for item, score in item_score_dict.items():\n",
    "        print(f\"{item}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "써브웨이(판교브릿지타워점): 0.5737663507461548\n",
      "오투닭갈비부대찌개(판교점): 0.22353306412696838\n",
      "닭갈비야(판교점): 0.21548983454704285\n",
      "연어랑 스테끼: 0.21266816556453705\n",
      "카츠소당: 0.2088238149881363\n",
      "광화문국밥(판교점): 0.20701460540294647\n",
      "(주)엔바이콘 아시안퀴진: 0.20222622156143188\n",
      "행복한집숯불갈비: 0.19879905879497528\n",
      "봉피양(판교점): 0.19253014028072357\n",
      "역전우동0410(판교역점): 0.1855875551700592\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations\n",
    "item_list = [\n",
    "    '킨파',\n",
    "    '서호돈가스',\n",
    "    '버거킹(판교유스페이스)',\n",
    "    '일상화식'\n",
    "]\n",
    "\n",
    "user_free_inference(item_list, df_user_item, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
